{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3714623-3493-4145-bcd6-069814440274",
   "metadata": {},
   "source": [
    "# SWIFT notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f7495-2a8b-4647-b882-f6207f4cfc40",
   "metadata": {},
   "source": [
    "You can find very detailed SWIFT documentation from this [link](http://swift.dur.ac.uk/docs/index.html). This notebook is only a very basic guide and should not be fully trusted. The choices of modules, compiler, MPI library and parameters is based on my previous test on BlueCrystal 4, BluePebble 1 and Trappist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e2a00-05f6-4fc5-9af2-f2b3551133b1",
   "metadata": {},
   "source": [
    "## <a name=\"top\"></a>Contents:\n",
    "[1. Compiling SWIFT](#S1) <br>\n",
    " * [Modules](#S11)<br>\n",
    " * [Configuration](#S12)<br>\n",
    " * [Compilation](#S13)<br>\n",
    " * [SLURM scripts](#S14)<br>\n",
    " * [Command line options](#S15)<br>\n",
    "\n",
    "[2. Parameter file](#S2)\n",
    "\n",
    "[3. Generating IC file](#S3)\n",
    "\n",
    "[4. Read and Analysis](#S4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0e6a6-8abe-4350-9b96-d77e5d059624",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce4780-4ee2-4226-aed7-e63b528f5717",
   "metadata": {},
   "source": [
    "## <a name=\"S1\"></a>**1. Compiling SWIFT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf367b0-c784-41fb-82f6-b5641f243f70",
   "metadata": {},
   "source": [
    "From [SWIFT gitlab](https://gitlab.cosma.dur.ac.uk/swift/swiftsim/-/tree/master) you can download the lastest version of SWIFT, it may fail to compile sometimes. If that's the case, try to download it from their [github](https://github.com/SWIFTSIM/swiftsim) which would be more stable. However, the lastest version means more fancy features, e.g. report of cpu dead time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3020c-812c-4f20-98ad-d661884ac15a",
   "metadata": {},
   "source": [
    "After downloading SWIFT, using following command to have an intial set up:\n",
    "```bash\n",
    "module purge\n",
    "module load libtool\n",
    "\n",
    "./autogen.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7361411-5508-4944-8d4e-751fcf84779d",
   "metadata": {},
   "source": [
    "First things first, choose a compiler and an MPI library. Based on the architechtures of the HPC you can choose to use either gcc or intel icc. However, if the HPC has an OmniPath, Open MPI v3.1.3 or higher is suggested to be used. A bug in the `psm2` library causes communications to be lost. It is possible to run SWIFT with older versions v2.1.x of Open MPI so long as `psm` is used instead of `psm2`, i.e. that you invoke mpirun with `--mca btl vader,self -mca mtl psm` (Only do this if normal mpirun is not working)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6e949-913f-40cb-8935-2faa8149db03",
   "metadata": {},
   "source": [
    "Below are the necessary modules needed to utilize the most basic functions of SWIFT:\n",
    "* HDF5 (SWIFT makes effective use of parallel HDF5 when running on more than one node, if possible, use a parallel version of HDF5 lib)\n",
    "* GSL\n",
    "* FFTW (SWIFT does not make use of the parallel capability of FFTW. Calculations are done by single MPI nodes independently.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ee186-12f3-45ab-9df3-c504c62053e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41108a29-3aa5-41cc-8872-5c62a12cb1ec",
   "metadata": {},
   "source": [
    "SWIFT can actually compile and run well with the above modules loaded, below are some bonus modules that can further optimize the code and the load balance on muti-core nodes. \n",
    "* ParMETIS/METIS (configure option: `--with-parmetis=/path/to/your/locally/installed/parmetis/lib`)\n",
    "    * BC4 and BP1 have ParMETIS installed but SWIFT can't link to it sometimes, one option is to install the ParMETIS lib locally on your home dir. Download from this [link](http://glaros.dtc.umn.edu/gkhome/metis/parmetis/download) and follow the install instruction. You should first go to the dir `/path/to/lib/parmetis-4.0.3/metis/include/` and edit the file `metis.h`. In the file, change the line 33 from `#define IDXTYPEWIDTH 32` to `#define IDXTYPEWIDTH 64`. After that, at the top of ParMetis' directory execute `make` and follow the instructions. Make sure you provide a installation prefix by using `make config prefix=/some/dir/for/parmetis` . After installation of ParMETIS, please also install METIS using the same installation prefix. Direct to `metis` dir and at the top of Metis' directory execute `make` and follow the instructions. \n",
    "* LibNUMA\n",
    "  * a build of the NUMA library can be used to pin the threads to the physical core of the machine SWIFT is running on. Normally no need to load  any modules on BC4 and PB1, but please use configure option:`--enable-compiler-warnings=yes` during  configuration step, otherwise, it will fail to compile(on bc4 and pb1).\n",
    "* tcmalloc / jemalloc / TBBmalloc: (configure option:`--with-tcmalloc`, `--with-jemalloc` , `--with-tbbmalloc`)\n",
    "  * a build of the tcmalloc library, jemalloc or TBBmalloc can be used to obtain faster and more scalable allocations than the standard C malloc function part of glibc. Using one of these is highly recommended on systems with many cores per node. Right now unavaiable on bc4, available on bp1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f61306-9163-4331-a964-229782572d84",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1615d40-6649-4fd1-a393-a1d5b5683bfe",
   "metadata": {},
   "source": [
    "### <a name=\"S11\"></a>**Modules**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f364d-52b2-4a18-b847-80be7ac77365",
   "metadata": {},
   "source": [
    "Below are the modules recipe I currently use on the BC4:\n",
    "```bash\n",
    "module purge\n",
    "module load apps/parmetis/4.0.3 \n",
    "module load libs/hdf5/1.10.1.MPI \n",
    "module load libs/fftw/3.3.6 \n",
    "module load libs/gsl/1.16-gcc-9.1.0 \n",
    "module load languages/intel/2020-u4\n",
    "\n",
    "module save swift_module\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc34c12b-af5b-4fa6-9f25-298b7c6f3552",
   "metadata": {},
   "source": [
    "### <a name=\"S12\"></a>**Configuration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a140d6-1e80-4b29-8473-800ef78304c2",
   "metadata": {},
   "source": [
    "For the planetary simulation, you could use the following configuration options:\n",
    "```\n",
    "./configure --with-hydro=planetary \\\n",
    "            --with-equation-of-state=planetary \\\n",
    "            --enable-compiler-warnings=yes \\\n",
    "            --with-gravity=basic \\\n",
    "            --with-parmetis=/mnt/storage/home/YourAccount/PathTo/parmetis \\\n",
    "            CC=icc \\ \n",
    "            MPICC=mpiicc\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f02c604-c6b3-47e6-9f11-8255a47670e2",
   "metadata": {},
   "source": [
    "* SWIFT default compiler is gcc but you can use `CC` environment variable to select the prefered compiler. `./configure CC=icc` to change to use Intel compiler.\n",
    "* The MPI compiler can be controlled using the `MPICC` variable, much like the `CC` one. \n",
    "* copy file `metis.h` from the `/dir/you/intall/parmetis/include` to `/dir/you/intall/swift/swiftsim/src/` would sometimes avoid the compilation error related to ParMETIS library. \n",
    "* You will need another SWIFT executable to run artificial cooling (velocity dumping is not included in the SWIFT). During configuration, add this option`--enable-planetary-fixed-entropy` will override the internal energy of each particle each step such that its specific entropy remains constant. Your initial conditions file must includes specific entropies for each particle in order to use this feature.\n",
    "* add `--with-tcmalloc` to the above configure command if it's available on your HPC.\n",
    "* `./configure --help` is pretty helpful, you can find all available options by using that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ab555-9dd3-4ddf-8103-e98311a4ce2c",
   "metadata": {},
   "source": [
    "### <a name=\"S13\"></a>**Compilation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b95210-81e5-4a36-86ea-33e9a900c681",
   "metadata": {},
   "source": [
    "After configuration, if everything works fine, your will get a configuartion summary list which you can use to have a double check of the libraries and features you used. \\\n",
    "You can then just use `make` to compile the code. If things go well, you will find two executble `swift` and `swift_mpi` in the `/swiftsim/example` directory. Run `swift` if you are only using one node. Use `swift_mpi` with one MPI rank per NUMA region (per socket) for muti-node job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a1488f-72d7-475f-8fb0-320bffe05bf9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad6b6d1-70ee-48d0-94f6-dbd2fbe85ba4",
   "metadata": {},
   "source": [
    "### <a name=\"S14\"></a>**SLURM scripts** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441df0d-5e36-4399-86cd-9bb9dd961dda",
   "metadata": {},
   "source": [
    "Below are some SLURM scripts used on BC4 where each node has two chips with each chip has 14 CPUs(so in total 28 CPUs per node)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe50048c-6280-4eff-b847-437a57235fd4",
   "metadata": {},
   "source": [
    "#### **<font color='green'>Single-node job with <font color='red'>all</font> cpus</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a3867b-d43c-469e-8b6b-179a462a5a90",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash -l\n",
    "\n",
    "#SBATCH -J swift_impact_1node28cpu \n",
    "#SBATCH --nodes 1\n",
    "#SBATCH --exclusive\n",
    "\n",
    "module purge \n",
    "module restore swift_module\n",
    "\n",
    "./swift -a -s -G -t 28 parameters_impact.yml\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcace506-5a05-4b6a-98d1-86baaaf7bf74",
   "metadata": {},
   "source": [
    " #### **<font color='green'>Single-node job with <font color='red'>partial</font> cpus</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcb984-ae34-4eaa-8107-a8174ef99797",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash -l\n",
    "\n",
    "#SBATCH -J swift_impact_1node20cpu \n",
    "#SBATCH --nodes 1\n",
    "#SBATCH --cpus-per-task=20        \n",
    "#SBATCH --tasks-per-node=1\n",
    "\n",
    "module purge\n",
    "module restore swift_module\n",
    "\n",
    "./swift -a -s -G -t 20 parameters_impact.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e6c134-3029-4adf-9aec-9b0a812b7162",
   "metadata": {},
   "source": [
    "#### **<font color='green'>Multi-node job with <font color='red'>all</font> cpus</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc839b1d-bab4-4782-a5f6-9dcbcc277736",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash -l\n",
    "\n",
    "#SBATCH -J swift_impact_2node56cpu\n",
    "#SBATCH --tasks-per-node=2\n",
    "#SBATCH --nodes 2\n",
    "#SBATCH --exclusive\n",
    "\n",
    "module purge\n",
    "module restore swift_module\n",
    "\n",
    "mpirun -np 4 ./swift_mpi -a -s -G -t 14 parameters_impact.yml \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3bf97d-64c5-44f4-8331-647314f03e72",
   "metadata": {},
   "source": [
    "#### **<font color='green'>Multi-node job with <font color='red'>partial</font> cpus</font>** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892d5429-8571-43cd-b2c7-1d401555a63d",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash -l\n",
    "\n",
    "#SBATCH -J swift_impact_2node32cpu\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --tasks-per-node=2\n",
    "#SBATCH --nodes 2\n",
    "\n",
    "module purge\n",
    "module restore swift_module\n",
    "\n",
    "mpirun -np 4 ./swift_mpi -a -s -G -t 8 parameters_impact.yml \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d076d3c-0dbd-4465-af2f-79da4b7d695e",
   "metadata": {},
   "source": [
    "### <a name=\"S15\"></a>**Command line options**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4376f3-5b28-4944-9129-c8d12a7ec4bc",
   "metadata": {},
   "source": [
    "* Above script only contains the very basic SLURM skeleton, you can always add other flags to limit the time, memory, partitions, emails, etc. \n",
    "* You can check the command line options list by using `./swift -h`. \n",
    "* Normally, for the planetary impact simulation, `-s` (stands for running with hydrodynamics) and `-G` (stands for running with self-gravity) are two must have options. \n",
    "* `-t <int>` is used to pass on the the number of task threads to use on each MPI rank. If you are running on one node, `-t` can be as large as the total number of threads or cpus the node has. See above \"Single-node job with all cpus\" script for example. If running with MPI, `-t` can be as large as the number of cpus per chip or socket has. See above \"Multi-node job with all cpus\" script for example. \n",
    "* Typically, HPC clusters now use two chips per node, so in the script, make sure you add `#SBATCH --tasks-per-node=2`, this will let SWIFT run with one MPI rank per NUMA region.\n",
    "* The `mpirun` comamnd should follow `mpirun -np <number of chips in total> ./swift_mpi -s -G -t <number of cpus(cores) per chip>`. Take BlueCrystal 4 as example: each node has two chips and each chips has 14 cpus, so if using 4 nodes in total ( 8 chips in total then ), it would be like `mpirun -np 8 ./swift_mpi -s -G -t 14`\n",
    "* Threads pinned. You can do this by passing the `-a` flag to the SWIFT binary. This ensures that processes stay on the same core that spawned them, ensuring that cache is accessed more efficiently.\n",
    "* Restart. If restart is enabled in the parameters file, you can just restart the job from the most recently generated restart file. Just pass `-r` flag to the SWIFT binary, i.e.,`./swift -r -s -G -t 24`\n",
    "* Verbose output. Verbose output can be enabled with `-v 1` flag. If runing muti-node job, `-v 2` can be used to output from all ranks. Be careful with the verbose output, logfile can be quit large and will take up all your home directories quota. Better to generate the logfile in the scrath space then.\n",
    "* Steps. If you want to use number of steps instead simulation time to control the job, pass `-n <int>` to the swift binary. Job will terminate after certain steps. This can be useful when combining with restart to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137f812-4973-476e-932e-4d13c5685cd0",
   "metadata": {},
   "source": [
    "[Back to Contents](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc117e-3a83-41dd-a5b3-fbcc2ad5ad5f",
   "metadata": {},
   "source": [
    "## <a name=\"S2\"></a>2. Parameter file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b714973-d41f-4a59-bd0d-205a38ef416e",
   "metadata": {},
   "source": [
    "```python\n",
    "# Define the system of units to use internally.\n",
    "InternalUnitSystem:\n",
    "    UnitMass_in_cgs:        5.97240e27         # Set the internal mass unit to Earth mass = 5.97240e27 g\n",
    "    UnitLength_in_cgs:      6.371e8            # Set the internal length unit to Earth radius = 6.371e8 cm\n",
    "    UnitVelocity_in_cgs:    6.371e8            # Set time in seconds (SWIFT set internal velocity insead of time)\n",
    "    UnitCurrent_in_cgs:     1.0                # Amperes\n",
    "    UnitTemp_in_cgs:        1.0                # Kelvin\n",
    "\n",
    "# Parameters related to the initial conditions\n",
    "InitialConditions:\n",
    "    file_name:  ./swift_impact.hdf5      # The initial conditions file to read\n",
    "    periodic:   0                        # Are we running with periodic ICs?\n",
    "\n",
    "# Parameters governing the time integration\n",
    "TimeIntegration:\n",
    "    time_begin:     0                   # The starting time of the simulation (in internal units).\n",
    "    time_end:       72000               # The end time of the simulation (in internal units).\n",
    "    dt_min:         0.0001              # The minimal time-step size of the simulation (in internal units).\n",
    "    dt_max:         1000                # The maximal time-step size of the simulation (in internal units).\n",
    "\n",
    "# Parameters governing the snapshots\n",
    "Snapshots:\n",
    "    basename:           snapshot        # Common part of the name of output files\n",
    "    time_first:         0               # Time of the first output (in internal units)\n",
    "    delta_time:         100             # Time difference between consecutive outputs (in internal units)\n",
    "    subdir:             ./output        # Output directory, will automatically generate one if not find at the start of the simulation   \n",
    "\n",
    "# Parameters governing the conserved quantities statistics\n",
    "Statistics:\n",
    "    time_first: 0                       # Time of the first output (in internal units)\n",
    "    delta_time: 1000                    # Time between statistics output\n",
    "\n",
    "# Parameters controlling restarts\n",
    "Restarts:\n",
    "    enable:         1                   # Whether to enable dumping restarts at fixed intervals.\n",
    "    save:           1                   # Whether to save copies of the previous set of restart files (named .prev)\n",
    "    onexit:         1                   # Whether to dump restarts on exit (*needs enable*)\n",
    "    subdir:         ./RESTART           # Name of subdirectory for restart files.\n",
    "    basename:       Rfile               # Prefix used in naming restart files.\n",
    "    delta_hours:    0.5                 # Decimal hours between dumps of restart files. NOTE!!! Unit change to hours(h) here.\n",
    "    \n",
    "SPH:\n",
    "    resolution_eta:     1.2348          # Target smoothing length in units of the mean inter-particle separation (1.2348 == 48Ngbs with the cubic spline kernel).\n",
    "    delta_neighbours:   0.1             # The tolerance for the targetted number of neighbours.\n",
    "    CFL_condition:      0.2             # Courant-Friedrich-Levy condition for time integration.\n",
    "    h_max:              0.08            # Maximal allowed smoothing length (in internal units). \n",
    "    viscosity_alpha:    1.5             # Override for the initial value of the artificial viscosity.\n",
    "\n",
    "# Parameters for the self-gravity scheme\n",
    "Gravity:\n",
    "    eta:                            0.025       # Constant dimensionless multiplier for time integration.\n",
    "    MAC:                            adaptive    # Choice of mulitpole acceptance criterion: 'adaptive' OR 'geometric'.\n",
    "    epsilon_fmm:                    0.001       # Tolerance parameter for the adaptive multipole acceptance criterion.\n",
    "    theta_cr:                       0.5         # Opening angle for the purely gemoetric criterion.\n",
    "    max_physical_baryon_softening:  0.05        # Physical softening length (in internal units).\n",
    "    use_tree_below_softening:       0           # Whether or not to use the approximate gravity from the FMM tree below the softening scale\n",
    "\n",
    "# Parameters governing domain decomposition\n",
    "DomainDecomposition:\n",
    "    trigger:        0.1                 # Fractional (<1) CPU time difference between MPI ranks required to trigger a new decomposition, or number of steps (>1)                                             # between decompositions \n",
    "    adaptive:         0                 # Use adaptive repartition when ParMETIS is available, otherwise simple refinement.\n",
    "    \n",
    "# Parameters that control how the cell tree is configured and defines some values for the related tasks. Tuning parameters, both for speed and memory use.\n",
    "Scheduler:\n",
    "    max_top_level_cells:    16         # Maximal number of top-level cells in any dimension. The number of top-level cells will be the cube of this. \n",
    "    cell_split_size:        400         # Maximal number of particles per cell (400 is the default value).\n",
    "    tasks_per_cell:         2.5         # The average number of tasks per cell. If not large enough the simulation will fail (means guess...). \n",
    "    links_per_tasks:        20          # number of links per task\n",
    "    mpi_message_limit:      4096        # Defines the size (in bytes) below which MPI communication will be sent using non-buffered calls.\n",
    "    nr_queues:              28          # Defines the number of task queues used. These are normally set to one per thread and should be at least that number.\n",
    "\n",
    "# Parameters related to the equation of state\n",
    "EoS:\n",
    "    # Select which planetary EoS material(s) to enable for use.\n",
    "    # Have a look at http://swift.dur.ac.uk/docs/Planetary/equations_of_state.html if you want to use other kind of EoS\n",
    "    \n",
    "    planetary_use_ANEOS_forsterite:       1     #  material id 400\n",
    "    planetary_use_ANEOS_iron:             1     #  material ID 401\n",
    "    planetary_ANEOS_forsterite_table_file:      ./ANEOS_forsterite_S19.txt\n",
    "    planetary_ANEOS_iron_table_file:            ./ANEOS_iron_S20.txt  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91dcecd-3b94-44ac-810f-7e3eb94bb408",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1088359d-fb80-488d-8da6-501453d7da4e",
   "metadata": {},
   "source": [
    "You will find a parameter file called `parameters_impact.yml` in the repository alongside with this notebook. Normally, you will need to change the following parameters:\n",
    "* `file_name`  what's the name of the initial condition hdf5 file\n",
    "* `time_end`   simulation time in second\n",
    "* `delta_time` Time difference in second between consecutive outputs\n",
    "* `subdir`     name of the output directory\n",
    "* `h_max` Particles with h larger than this h_max limit will be capped and are effectively treated as just balistic objects. Currently, we use 5%~10% of the radius of the largest planet in the simulation as the value for h_max. h_max will greatly affect the speed of SWIFT in terms of planetary impact. Current experience is that do not use `h_max` larger than 1/6 of the boxsize, otherwise a potential bug in SWIFT would occur and the simulation result is bad. If you turn verbose output on, you might notice the reported `h_max` is different than what you set initially in the parameter file, this is because the `h_max` reported here is the maximum smoothing length among all the gas particles at this step. It's different because the largest smoothing length at current step is still less than the limit you set in parameter file. `h_max` and `cell_min` are all in internal unit. Some of the discussion about h_max can be found [here](https://github.com/SWIFTSIM/swiftsim/issues/22).\n",
    "* `max_top_level_cells` Normally set to 16 and only make it larger if the gravity solver gets very slow.\n",
    "* `tasks_per_cell` Need a larger value e.g. 3.0, if using high resolution but not enough number of cpus. \n",
    "* `nr_queues`  Set to one per thread and should be at least that number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560b9f63-6a0e-4a77-9b6b-794df7e2b399",
   "metadata": {},
   "source": [
    "[Back to Contents](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c3f16-b011-4e31-9ab6-7cd0b497d493",
   "metadata": {},
   "source": [
    "## <a name=\"S3\"></a>3. Generating IC file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd971a6-cef6-4771-b8ea-50bbe3af368b",
   "metadata": {},
   "source": [
    "All the initial condition file from my tests are generated using the WOMA module. You can find a jupyter notebook tutorial from their [github](https://github.com/srbonilla/WoMa). You need to install WOMA if you want to use it to generate your IC file, otherwise, you can use the swiftsimio python package to generate the IC file directly. Here is the swiftsimio [github](https://github.com/SWIFTSIM/swiftsimio) and [documentation](https://swiftsimio.readthedocs.io/en/latest/index.html). swiftsimio is more often used to load the swift hdf5 data, check this [link](https://swiftsimio.readthedocs.io/en/latest/loading_data/index.html) to know how to load data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e319908a-449e-4523-880e-2679a3416df9",
   "metadata": {},
   "source": [
    "NOTE!!! WOMA use <font color='red'> mks unit system </font>while Gadget2 use cgs, so please always be careful with the unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7855d3c-7c17-4fc1-9a15-452195660db5",
   "metadata": {},
   "source": [
    "Below is a very simple example of how to use WOMA to generate a two-layer planetsimal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61bdd95e-e6f8-4436-aeed-4b3b9a4300c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import woma\n",
    "import swiftsimio as sw\n",
    "import numpy as np\n",
    "import unyt\n",
    "import h5py\n",
    "R_earth = 6.371e6   # m\n",
    "M_earth = 5.9724e24  # kg m^-3 \n",
    "G = 6.67408e-11  # m^3 kg^-1 s^-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841c7520-3991-409b-b711-d6a81b1ed1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to build a planet with R=R_min... Success\n",
      "Trying to build a planet with R=R_max... Success\n",
      "Iter 9(40): R=1.0244R_E R1=0.51271R_E: tol=0.0003(0.001)  \n",
      "Tweaking M to avoid density peaks at the center of the planet... Done\n",
      "Planet \"target_planet\": \n",
      "    M            = 5.9657e+24  kg  = 0.99888  M_earth\n",
      "    R            = 6.5265e+06  m  = 1.0244  R_earth\n",
      "    mat          = [\"ANEOS_iron\", \"ANEOS_forsterite\"] \n",
      "    mat_id       = [401, 400] \n",
      "    T_rho_type   = [\"entropy=1500\", \"entropy=3500\"] \n",
      "    R_layer      = [0.51169, 1.0244]  R_earth\n",
      "    M_layer      = [0.29899, 0.69989]  M_earth\n",
      "    M_frac_layer = [0.29933, 0.70067]  M_tot\n",
      "    idx_layer    = [499, 999] \n",
      "    P_s          = 10000  Pa\n",
      "    T_s          = 1500  K\n",
      "    rho_s        = 3110.5  kg m^-3\n",
      "    P_1          = 1.4014e+11  Pa\n",
      "    T_1          = 2738.2  K\n",
      "    rho_1        = 11156  kg m^-3\n",
      "    P_0          = 3.8559e+11  Pa\n",
      "    T_0          = 3588.6  K\n",
      "    rho_0        = 13797  kg m^-3\n",
      "    I_MR2        = 0.32451  M_tot*R_tot^2\n"
     ]
    }
   ],
   "source": [
    "planet = woma.Planet(\n",
    "    name            = \"target_planet\",\n",
    "    A1_mat_layer    = [\"ANEOS_iron\", \"ANEOS_forsterite\"], # check the name of different material and EoS at: https://github.com/srbonilla/WoMa/blob/master/woma/misc/glob_vars.py\n",
    "    A1_T_rho_type   = [\"entropy=1500\", \"entropy=3500\"],   # Here I use fixed entropy for each layer, other option: \"adiabatic\",\"power=<float>\"\n",
    "    P_s             = 1e4,                                # Surface pressure\n",
    "    T_s             = 1500,                               # Surface temperature\n",
    "    A1_M_layer      = [0.3*M_earth, 0.7*M_earth],         # Masses of each layer\n",
    ")\n",
    "planet.gen_prof_L2_find_R_R1_given_M1_M2(R_min=0.95*R_earth, R_max=1.05 * R_earth) # This will only generate the radius profile\n",
    "planet_particles = woma.ParticlePlanet(planet, 5e4, verbosity=0) # This will place 5e4 particles based on the profile generated at last step.\n",
    "                                                                 # Note the final total number of particles can not be controled and this is \n",
    "                                                                 # caused by their tuning method of WOMA.\n",
    "# Save to the hdf5 file\n",
    "filename='/data/storage/planet.hdf5'\n",
    "planet_particles.save(\n",
    "    filename=filename,\n",
    "    boxsize=10*R_earth,                                         # set the boxsize\n",
    "    file_to_SI=woma.Conversions(M_earth, R_earth, 1),           # This will use the earth radius and mass as the storage unit\n",
    "    #file_to_SI=utils.SI_to_cgs                                 # You can convert to cgs unit using this command instead\n",
    "    do_entropies=True)                                          # If you want to use entropy forcing, make sure \"do_entropies\" is set to True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2513c73-0001-485b-b1c4-bd05ff3e9bf7",
   "metadata": {},
   "source": [
    "Here is the temperature and density power law relationship if you choose to use `A1_T_rho_type=[\"power=alpha\"] `$T\\propto\\rho^\\alpha$ ($\\alpha=0$ for isothermal).\n",
    "You could then use SWIFT to equilibrate the planetsimals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70961aeb-f514-48b0-b99f-5e606dc4f073",
   "metadata": {},
   "source": [
    "After artifical cooling and relax check. You could use the following code to load the SWIFT snapshot and convert the different instance to the mks unit used by WOMA. For detailed document, check swiftsimio [guid](https://swiftsimio.readthedocs.io/en/latest/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe0622f-a9f6-46bd-bb84-e047278df51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_woma(snapshot):\n",
    "    # Load\n",
    "    data    = sw.load(snapshot)\n",
    "    \n",
    "    data.gas.coordinates.convert_to_mks()\n",
    "    data.gas.velocities.convert_to_mks()\n",
    "    data.gas.smoothing_lengths.convert_to_mks()\n",
    "    data.gas.masses.convert_to_mks()\n",
    "    data.gas.densities.convert_to_mks()\n",
    "    data.gas.pressures.convert_to_mks()\n",
    "    data.gas.internal_energies.convert_to_mks()\n",
    "    box_mid = 0.5*data.metadata.boxsize[0].to(unyt.m)\n",
    "\n",
    "    pos     = np.array(data.gas.coordinates - box_mid)\n",
    "    vel     = np.array(data.gas.velocities)\n",
    "    h       = np.array(data.gas.smoothing_lengths)\n",
    "    m       = np.array(data.gas.masses)\n",
    "    rho     = np.array(data.gas.densities)\n",
    "    p       = np.array(data.gas.pressures)\n",
    "    u       = np.array(data.gas.internal_energies)\n",
    "    matid   = np.array(data.gas.material_ids)\n",
    "    \n",
    "    pos_centerM = np.sum(pos * m[:,np.newaxis], axis=0) / np.sum(m)\n",
    "    vel_centerM = np.sum(vel * m[:,np.newaxis], axis=0) / np.sum(m)\n",
    "    \n",
    "    pos -= pos_centerM\n",
    "    vel -= vel_centerM\n",
    "    \n",
    "    xy = np.hypot(pos[:,0],pos[:,1])\n",
    "    r  = np.hypot(xy,pos[:,2])\n",
    "    r  = np.sort(r)\n",
    "    R  = np.mean(r[-100:])\n",
    "    \n",
    "    return pos, vel, h, m, rho, p, u, matid, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17b3e5-8e96-45db-84c5-e9870ff02048",
   "metadata": {},
   "source": [
    "You could use the following code to load and generate a complete impact simulation initial condition file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f9df618-e5fd-440a-88dd-6f8690020bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tar='/data/trappist1/Jingyao/swift/planetary/pb1data/output_swift_05715_65e5_EF_10h/snapshot_0360.hdf5'\n",
    "loc_imp='/data/trappist1/Jingyao/swift/planetary/pb1data/output_swift_0468_65e5_EF_10h/snapshot_0360.hdf5'\n",
    "\n",
    "pos_tar, vel_tar, h_tar,m_tar, rho_tar, p_tar, u_tar, matid_tar,pid_tar, R_tar = load_to_woma(loc_tar)\n",
    "pos_imp, vel_imp, h_imp,m_imp, rho_imp, p_imp, u_imp, matid_imp,pid_imp, R_imp = load_to_woma(loc_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51a847bf-a266-4c2d-bf75-bad0c6f5afee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of particles in target 645646\n",
      "\n",
      "num_particle = 1290680\n",
      "boxsize      = 1e+02\n",
      "mat_id       = 400 401 \n",
      "\n",
      "Unit mass    = 5.97240e+27 g\n",
      "Unit length  = 6.37100e+08 cm\n",
      "Unit time    = 1.00000e+00 s\n",
      "\n",
      "Min, max values (file units):\n",
      "  pos = [45.589, 55.151,    48.562, 51.518,    49.143, 50.858]\n",
      "  vel = [-0.0012135, 0.00099127,    -0.00018171, 0.00021851,    -2.4332e-05, 2.4174e-05]\n",
      "  m = 7.2158e-07, 8.8378e-07\n",
      "  rho = 0.1355, 0.53601\n",
      "  P = 6.1353e-10, 2.5155e-07\n",
      "  u = 2.8456e-08, 1.693e-07\n",
      "  h = 0.01383, 0.023054\n",
      "\n",
      "Saved \"o/swift/planetary/ics/impact_05715_0468_65e5_9d7_055_100box.hdf5\"\n"
     ]
    }
   ],
   "source": [
    "M_t = np.sum(m_tar)\n",
    "M_i = np.sum(m_imp)\n",
    "R_t = R_tar\n",
    "R_i = R_imp\n",
    "\n",
    "# Mutual escape speed\n",
    "v_esc = np.sqrt(2 * G * (M_t + M_i) / (R_t + R_i))\n",
    "\n",
    "# Initial position and velocity of the target\n",
    "A1_pos_t = np.array([0., 0., 0.])\n",
    "A1_vel_t = np.array([0., 0., 0.])\n",
    "\n",
    "A1_pos_i, A1_vel_i = woma.impact_pos_vel_b_v_c_t(\n",
    "    b       = 0.3,\n",
    "    v_c     = 3.0 * v_esc, \n",
    "    t       = 3600, \n",
    "    R_t     = R_t, \n",
    "    R_i     = R_i, \n",
    "    M_t     = M_t, \n",
    "    M_i     = M_i,\n",
    ")\n",
    "\n",
    "A1_pos_com = (M_t * A1_pos_t + M_i * A1_pos_i) / (M_t + M_i)\n",
    "A1_pos_t -= A1_pos_com\n",
    "A1_pos_i -= A1_pos_com\n",
    "\n",
    "# Centre of momentum\n",
    "A1_vel_com = (M_t * A1_vel_t + M_i * A1_vel_i) / (M_t + M_i)\n",
    "A1_vel_t -= A1_vel_com\n",
    "A1_vel_i -= A1_vel_com\n",
    "\n",
    "pos_tar += A1_pos_t\n",
    "vel_tar[:] += A1_vel_t\n",
    "\n",
    "pos_imp += A1_pos_i\n",
    "vel_imp[:] += A1_vel_i\n",
    "\n",
    "\n",
    "with h5py.File(\"/loc/of/your/dir/foo.hdf5\", \"w\") as f:\n",
    "    woma.save_particle_data(\n",
    "        f,\n",
    "        np.append(pos_tar, pos_imp, axis=0),\n",
    "        np.append(vel_tar, vel_imp, axis=0),\n",
    "        np.append(m_tar, m_imp),\n",
    "        np.append(h_tar, h_imp),\n",
    "        np.append(rho_tar, rho_imp),\n",
    "        np.append(p_tar, p_imp),\n",
    "        np.append(u_tar, u_imp),\n",
    "        np.append(matid_tar, matid_imp),\n",
    "        boxsize=100 * R_earth,\n",
    "        file_to_SI=woma.Conversions(M_earth, R_earth, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9caca-c1de-4483-8434-7c0778716086",
   "metadata": {},
   "source": [
    "[Back to Contents](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83916cb5-31a5-4224-aa7f-39389ae85399",
   "metadata": {},
   "source": [
    "## <a name=\"S4\"></a>4. Read and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e1a82a-6006-444c-9010-a492dd71e8c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'woma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8719476aaa68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwoma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_eos_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load the eos table for the calculation of entropy at later stage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msw_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max_lim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEntropy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midealgas\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#woma.load_eos_tables()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'woma' is not defined"
     ]
    }
   ],
   "source": [
    "woma.load_eos_tables() # load the eos table for the calculation of entropy at later stage\n",
    "\n",
    "def sw_load(file_loc, ax_lim=1.3, Entropy=True, idealgas= False, center=True):\n",
    "    # Load\n",
    "    #woma.load_eos_tables()\n",
    "    \n",
    "   \n",
    "    data    = sw.load(file_loc)\n",
    "    box_mid = 0.5*data.metadata.boxsize[0]\n",
    "    pos     = data.gas.coordinates - box_mid\n",
    "    pos =np.array(pos)\n",
    "    data.gas.densities.convert_to_cgs()\n",
    "    rho_cgs = np.array(data.gas.densities)\n",
    "    data.gas.densities.convert_to_mks()\n",
    "    rho_mks = np.array(data.gas.densities)\n",
    "    data.gas.pressures.convert_to_cgs()\n",
    "    p       = np.array(data.gas.pressures)\n",
    "    data.gas.internal_energies.convert_to_mks()\n",
    "    u       = np.array(data.gas.internal_energies)\n",
    "    matid   = data.gas.material_ids\n",
    "    data.gas.pressures.convert_to_mks()\n",
    "    p_mks   = np.array(data.gas.pressures)\n",
    "    matid   = np.array(matid)\n",
    "    \n",
    "    colour = np.empty(len(matid), dtype=object)\n",
    "    for id_c, c in Di_id_colour.items():\n",
    "        colour[matid == id_c] = c\n",
    "\n",
    "    \n",
    "    entropy = np.zeros_like(p)\n",
    "    T       = np.zeros_like(p)\n",
    "    \n",
    "    if center:\n",
    "        #data.gas.masses.convert_to_mks()\n",
    "        m       = np.array(data.gas.masses)\n",
    "        pos_centerM = np.sum(pos * m[:,np.newaxis], axis=0) / np.sum(m)\n",
    "        #vel_centerM = np.sum(vel * m[:,np.newaxis], axis=0) / np.sum(m)\n",
    "    \n",
    "        pos -= pos_centerM\n",
    "        #vel -= vel_centerM\n",
    "    \n",
    "    if Entropy:\n",
    "        sel = np.logical_and(matid!=200, matid!=0)  \n",
    "        entropy[sel] = woma.eos.eos.A1_s_u_rho(u[sel],rho_mks[sel],matid[sel])*1e4\n",
    "        #T       = woma.eos.eos.A1_T_u_rho(u,rho_mks,matid)\n",
    "        \n",
    "    \n",
    "    T       = woma.eos.eos.A1_T_u_rho(u,rho_mks,matid)\n",
    "    \n",
    "    XY = np.hypot(pos[:,0],pos[:,1]) \n",
    "    R  = np.hypot(XY,pos[:,2])\n",
    "           \n",
    "    print('Read %d particles!'%(len(R)))\n",
    "    \n",
    "    return T, entropy, u, rho_cgs, p_mks, R, colour, matid\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0790e1-6565-4f6f-9217-0be5fa978aee",
   "metadata": {},
   "source": [
    "Below code could be used to load and plot data from SWIFT simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799ffb5-8b83-4035-8be7-bfdace50aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outtime   =500\n",
    "txtsize   =15\n",
    "font_size = 20\n",
    "idoff     = 200000000\n",
    "bodyoff   = 100000000\n",
    "\n",
    "params = {\n",
    "    \"axes.labelsize\"  : font_size,\n",
    "    \"font.size\"       : font_size,\n",
    "    \"xtick.labelsize\" : font_size,\n",
    "    \"ytick.labelsize\" : font_size,\n",
    "    \"font.family\"     : \"serif\",\n",
    "}\n",
    "matplotlib.rcParams.update(params)\n",
    "\n",
    "# Material IDs ( = type_id * type_factor + unit_id )\n",
    "type_factor  = 100\n",
    "type_Til     = 4\n",
    "type_HHe     = 2\n",
    "type_SESAME  = 3\n",
    "type_idg     = 0\n",
    "id_body      = 200000000\n",
    "# Name and ID\n",
    "Di_mat_id = {\n",
    "    \"ANEOS_iron\"     : type_Til * type_factor + 1 ,\n",
    "    \"ANEOS_iron_2\"   : type_Til * type_factor + 1 + id_body,\n",
    "    \"ANEOS_alloy\"    : type_Til * type_factor + 2 ,\n",
    "    \"ANEOS_alloy_2\"  : type_Til * type_factor + 2 + id_body,\n",
    "    \"ANEOS_granite\"  : type_Til * type_factor ,\n",
    "    \"ANEOS_granite_2\": type_Til * type_factor + id_body,\n",
    "    \"HM80_HHE\"       : type_HHe * type_factor,\n",
    "    \"SS08_water\"     : type_SESAME * type_factor + 3,\n",
    "    \"AQUA\"           : type_SESAME * type_factor + 4,\n",
    "    \"CMS19_HHe\"      : type_SESAME * type_factor + 7,\n",
    "    \"idg_HHe\"        : type_idg * type_factor,\n",
    "}\n",
    "# Colour\n",
    "Di_mat_colour = {\n",
    "    \"ANEOS_iron\"     : \"tomato\",\n",
    "    \"ANEOS_alloy\"    : \"tomato\",\n",
    "    \"ANEOS_granite\"  : \"mediumseagreen\",\n",
    "    \"ANEOS_iron_2\"   : \"sandybrown\",\n",
    "    \"ANEOS_alloy_2\"  : \"sandybrown\",\n",
    "    \"ANEOS_granite_2\": \"pink\",\n",
    "    \"SS08_water\"     : \"skyblue\",\n",
    "    \"AQUA\"           : \"skyblue\",\n",
    "    \"HM80_HHE\"       : \"lavenderblush\",\n",
    "    \"CMS19_HHe\"      : \"lavenderblush\",\n",
    "    \"idg_HHe\"        : \"lavenderblush\",\n",
    "}\n",
    "# marker size\n",
    "Di_mat_size = {\n",
    "    \"ANEOS_iron\"     : 1,\n",
    "    \"ANEOS_alloy\"    : 1,\n",
    "    \"ANEOS_granite\"  : 1,\n",
    "    \"ANEOS_alloy_2\"  : 1,\n",
    "    \"ANEOS_iron_2\"   : 1,\n",
    "    \"ANEOS_granite_2\": 1,\n",
    "    \"HM80_HHE\"       : 1,\n",
    "    \"SS08_water\"     : 1,\n",
    "    \"AQUA\"           : 1,\n",
    "    \"CMS19_HHe\"      : 1,\n",
    "    \"idg_HHe\"        : 1,\n",
    "}\n",
    "\n",
    "Di_id_colour = {Di_mat_id[mat]: colour for mat, colour in Di_mat_colour.items()}\n",
    "\n",
    "Di_id_size = {Di_mat_id[mat]: size*3.5 for mat, size in Di_mat_size.items()}\n",
    "\n",
    "# density limits\n",
    "rhomin=5e-5\n",
    "rhomax=15.\n",
    "\n",
    "# entropy limits\n",
    "cmin=1.5\n",
    "cmax=12.\n",
    "\n",
    "# number of cells for grid\n",
    "Ng=601j\n",
    "Ngz=21j\n",
    "\n",
    "# region to grid/plot\n",
    "xmax=3\n",
    "xmin=-xmax\n",
    "ymin=-xmax\n",
    "ymax=xmax\n",
    "zmin=-3\n",
    "zmax=3\n",
    "\n",
    "zcut=6.\n",
    "\n",
    "def sw_plot(loc, snapshot_id, npt=1e9, ax_lim=3.0,offcenter=0, text=False, midplane=False,rhocontour=False, quarter=False, belowZ=True, figsz=10):\n",
    "    \"\"\" Select and load the particles to plot. \"\"\"\n",
    "    # Snapshot to load\n",
    "    snapshot = \"snapshot_%04d.hdf5\" % snapshot_id\n",
    "\n",
    "    # Only load data with the axis limits and below z=0\n",
    "    mask = sw.mask(loc+snapshot)\n",
    "    box_mid = 0.5 * mask.metadata.boxsize[0].to(unyt.Rearth)\n",
    "    \n",
    "    # Load\n",
    "    data = sw.load(loc+snapshot)\n",
    "    pos = data.gas.coordinates.to(unyt.Rearth) - box_mid\n",
    "    id = data.gas.particle_ids\n",
    "    mat_id = data.gas.material_ids.value\n",
    "    m  = data.gas.masses\n",
    "\n",
    "    if rhocontour:\n",
    "        s=Snapshot()\n",
    "        zi=np.linspace(zmin,zmax,int(Ngz.imag))\n",
    "        X,Y,Z = np.mgrid[xmin:xmax:(Ng),ymin:ymax:(Ng),zmin:zmax:(Ngz)]\n",
    "        XX,YY = np.mgrid[xmin:xmax:(Ng),ymin:ymax:(Ng)]\n",
    "\n",
    "        cmap=plt.get_cmap('plasma').copy()\n",
    "        cmap.set_under('w')\n",
    "\n",
    "        data.gas.velocities.convert_to_cgs()\n",
    "        vel = np.array(data.gas.velocities)\n",
    "\n",
    "        data.gas.densities.convert_to_cgs()\n",
    "        rho_cgs=np.array(data.gas.densities)\n",
    "        \n",
    "        s.pot=data.gas.potentials\n",
    "        s.vel=np.array(vel)\n",
    "        s.vx=np.array(vel[:,0])\n",
    "        s.vy=np.array(vel[:,1])\n",
    "        s.vz=np.array(vel[:,2])\n",
    "        s.x=np.array(pos[:,0])\n",
    "        s.y=np.array(pos[:,1])\n",
    "        s.z=np.array(pos[:,2])\n",
    "        s.rho=np.array(rho_cgs)\n",
    "        \n",
    "        modz = np.abs(s.z)\n",
    "    \n",
    "        vcut=2*s.vel.max()\n",
    "        \n",
    "        rhoi = scipy.interpolate.griddata((s.x[(s.vx<vcut)*(modz<zcut)],s.y[(s.vx<vcut)*(modz<zcut)],s.z[(s.vx<vcut)*(modz<zcut)]),\\\n",
    "                                          s.rho[(s.vx<vcut)*(modz<zcut)],(X,Y,Z),method='linear',fill_value=1.e-18)\n",
    "        \n",
    "        coz = (s.z[s.pot==s.pot.min()])[0] #s.z[modz<zcut]\n",
    "        nn=(npy.nonzero(zi==(zi[zi<=coz])[-1])[0])[0]\n",
    "\n",
    "        RHO_sh=rhoi[:,:,nn].T\n",
    "        step = 0.8\n",
    "        m = np.amax(RHO_sh)\n",
    "        levels = np.arange(1.0, m, step)\n",
    "\n",
    "    pos_centerM = np.sum(pos * m[:,np.newaxis], axis=0) / np.sum(m)\n",
    "    pos -= pos_centerM\n",
    "    \n",
    "    if midplane:\n",
    "        sel    = np.where(np.logical_and(pos[:, 2] < 0.1, pos[:, 2] > -0.1))[0]\n",
    "        mat_id = mat_id[sel]\n",
    "        m      = m[sel]\n",
    "        id     = id[sel]\n",
    "        pos    = pos[sel]\n",
    "   \n",
    "    \n",
    "    #Restrict to z < 0\n",
    "    elif belowZ:\n",
    "        sel    = np.where(np.logical_and(pos[:, 2] < 0.1, pos[:, 2] > -6))[0]\n",
    "        mat_id = mat_id[sel]\n",
    "        id     = id[sel]\n",
    "        m      = m[sel]\n",
    "        pos    = pos[sel]\n",
    "\n",
    "    # Sort in z order so higher particles are plotted on top\n",
    "    sort   = np.argsort(pos[:, 2])\n",
    "    mat_id = mat_id[sort]\n",
    "    id     = id[sort]\n",
    "    m      = m[sort]\n",
    "    pos    = pos[sort]\n",
    "    \n",
    "    \n",
    "    if npt>0:\n",
    "        mat_id[npt<=id]+=id_body\n",
    "    else:\n",
    "        mat_id[np.logical_and(id<=2*idoff,id>idoff+bodyoff)] += id_body\n",
    "        mat_id[np.logical_and(id<=idoff,id>bodyoff)] += id_body\n",
    "    \n",
    "    impactor_core   = np.logical_and(mat_id==Di_mat_id[\"ANEOS_iron_2\"], pos[:,1]<-2)\n",
    "    target_core     = mat_id==Di_mat_id[\"ANEOS_iron\"]\n",
    "    impactor_mantle = mat_id==Di_mat_id[\"ANEOS_granite_2\"]\n",
    "    target_mantle   = mat_id==Di_mat_id[\"ANEOS_granite\"]\n",
    "    \n",
    "    #Plot the particles, coloured by their material.\n",
    "    fig = plt.figure(num=1, clear=True,figsize=(figsz, figsz))\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    colour = np.empty(len(pos), dtype=object)\n",
    "    for id_c, c in Di_id_colour.items():\n",
    "        colour[mat_id == id_c] = c\n",
    "\n",
    "    size = np.empty(len(pos), dtype=float)\n",
    "    for id_s, s in Di_id_size.items():\n",
    "        size[mat_id == id_s] = s\n",
    "    print(np.unique(mat_id))    \n",
    "    print(set(colour))\n",
    "    #return pos, size, colour, impactor_core\n",
    "    ax.scatter(\n",
    "        pos[:, 0],\n",
    "        pos[:, 1],\n",
    "        s=1*size,\n",
    "        c=colour,\n",
    "        edgecolors=\"none\",\n",
    "        marker=\".\",\n",
    "        alpha=1,\n",
    "    )\n",
    "   \n",
    "   \n",
    "#     ax.scatter(pos[target_mantle,0],pos[target_mantle,1],s=1,c='mediumseagreen',edgecolors=\"none\")\n",
    "    ax.scatter(pos[impactor_core,0],pos[impactor_core,1],s=1,c='sandybrown',edgecolors=\"none\")\n",
    "#     ax.scatter(pos[target_core,0],pos[target_core,1],s=1,c='tomato',edgecolors=\"none\")\n",
    "    if rhocontour:\n",
    "        con = ax.contour(XX,YY,RHO_sh, levels, origin='lower',extent=[-ax_lim,ax_lim,-ax_lim,ax_lim],alphas=0,cmap='YlGn')\n",
    "    \n",
    "    #ax.set_title('0.897 $M_\\oplus$ Protoearth with 1.2% $M_{total}$ atmosphere ')\n",
    "    ax.set_xlim(-(ax_lim+offcenter), ax_lim-offcenter)\n",
    "    ax.set_yticks(ax.get_xticks())\n",
    "    ax.set_ylim(-ax_lim, ax_lim)\n",
    "    ax.set_xlabel(r\"x Position ($R_\\oplus$)\")\n",
    "    ax.set_ylabel(r\"y Position ($R_\\oplus$)\")\n",
    "    \n",
    "    ax.yaxis.label.set_color('w')\n",
    "    ax.xaxis.label.set_color('w')\n",
    "    ax.tick_params(axis='x', colors='w',labelsize=14)\n",
    "    ax.tick_params(axis='y', colors='w',labelsize=14)\n",
    "    \n",
    "    if quarter:\n",
    "        ax.set_xlim(0, ax_lim+0.2)\n",
    "        ax.set_ylim(0, ax_lim+0.2)\n",
    "    \n",
    "        \n",
    "    if text:\n",
    "        ax.text(0.97,0.97,r'v = 9.17km/s, b = 0.7            {0:6.2f} h'.format(snapshot_id*outtime/3600),\n",
    "                     transform=ax.transAxes,ha='right',va='top',fontsize=txtsize,color='w')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # save = loc + \"plot/snaplot_%04d.png\" % snapshot_id\n",
    "    # plt.savefig(save)\n",
    "    plt.cla()\n",
    "    plt.clf() \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb8631-bf19-469c-afb3-205724d0d6c6",
   "metadata": {},
   "source": [
    "[Back to Contents](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hammer",
   "language": "python",
   "name": "hammer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
